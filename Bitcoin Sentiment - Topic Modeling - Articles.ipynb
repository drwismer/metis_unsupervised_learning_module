{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitcoin Sentiment Analysis - News Article Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key Resource - Topic Modeling with Gensim\n",
    "\n",
    "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from itertools import product\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set random state variable\n",
    "rs = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the combined and cleaned dataset\n",
    "with open('sentiment_pickles/pickle_articles_modeling.pickle', 'rb') as read_file:\n",
    "    bitcoin_articles = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape Data for Latent Dirilecht Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def article_to_words(articles):\n",
    "    for article in articles:\n",
    "        yield(gensim.utils.simple_preprocess(str(article), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "def remove_stopwords(articles):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in articles]\n",
    "\n",
    "def make_bigrams(articles):\n",
    "    return [bigram_mod[doc] for doc in articles]\n",
    "\n",
    "def make_trigrams(articles):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in articles]\n",
    "\n",
    "def lemmatization(articles, allowed_pos_tags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    lemmatized = []\n",
    "    for doc in articles:\n",
    "        doc = nlp(\" \".join(doc)) \n",
    "        lemmatized.append([token.lemma_ for token in doc if token.pos_ in allowed_pos_tags])\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \\n and \\xa0\n",
    "bitcoin_articles['body'] = bitcoin_articles['body'].str.replace('\\n', ' ')\n",
    "bitcoin_articles['body'] = bitcoin_articles['body'].str.replace('\\xa0', ' ')\n",
    "\n",
    "# Convert articles to words\n",
    "data = list(bitcoin_articles['body'])\n",
    "data_words = list(article_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Modify bigram and trigram for speed\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Form Trigrams\n",
    "data_words_trigrams = make_trigrams(data_words_bigrams)\n",
    "\n",
    "# Initialize spacy 'en_core_web_sm' model\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize and keep nouns, adjectives, verbs, and adverbs\n",
    "data_lemmatized = lemmatization(data_words_trigrams, allowed_pos_tags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create term document frequency Matrix (corpus)\n",
    "texts = data_lemmatized\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the term document frequency matrix (corpus)\n",
    "with open('sentiment_pickles/pickle_corpus_pre_PCA.pickle', 'wb') as to_write:\n",
    "    pickle.dump(corpus, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the term document frequency matrix (corpus)\n",
    "with open('sentiment_pickles/pickle_corpus_pre_PCA.pickle', 'rb') as read_file:\n",
    "    corpus = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Most Frequent and Infrequent Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with all words and the number of articles in which they appear\n",
    "word_index = list(id2word.dfs.keys())\n",
    "word = [id2word[wi] for wi in word_index]\n",
    "num_articles = list(id2word.dfs.values())\n",
    "total_articles = len(bitcoin_articles)\n",
    "\n",
    "word_doc_count = pd.DataFrame({'word_index' : word_index, 'word' : word, 'num_articles' : num_articles})\n",
    "word_doc_count['perc_articles'] = word_doc_count['num_articles'] / total_articles\n",
    "word_doc_count = word_doc_count.sort_values('num_articles', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_index</th>\n",
       "      <th>word</th>\n",
       "      <th>num_articles</th>\n",
       "      <th>perc_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>bitcoin</td>\n",
       "      <td>18820</td>\n",
       "      <td>0.995925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>also</td>\n",
       "      <td>13681</td>\n",
       "      <td>0.723977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>213</td>\n",
       "      <td>time</td>\n",
       "      <td>12870</td>\n",
       "      <td>0.681060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>1806</td>\n",
       "      <td>btc</td>\n",
       "      <td>12567</td>\n",
       "      <td>0.665026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>1691</td>\n",
       "      <td>cryptocurrency</td>\n",
       "      <td>11761</td>\n",
       "      <td>0.622374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>273</td>\n",
       "      <td>market</td>\n",
       "      <td>11631</td>\n",
       "      <td>0.615495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>196</td>\n",
       "      <td>say</td>\n",
       "      <td>11077</td>\n",
       "      <td>0.586178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55</td>\n",
       "      <td>new</td>\n",
       "      <td>10741</td>\n",
       "      <td>0.568397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>1250</td>\n",
       "      <td>price</td>\n",
       "      <td>10561</td>\n",
       "      <td>0.558872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>308</td>\n",
       "      <td>year</td>\n",
       "      <td>10450</td>\n",
       "      <td>0.552998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_index            word  num_articles  perc_articles\n",
       "7             13         bitcoin         18820       0.995925\n",
       "38             1            also         13681       0.723977\n",
       "182          213            time         12870       0.681060\n",
       "1823        1806             btc         12567       0.665026\n",
       "1706        1691  cryptocurrency         11761       0.622374\n",
       "282          273          market         11631       0.615495\n",
       "125          196             say         11077       0.586178\n",
       "5             55             new         10741       0.568397\n",
       "707         1250           price         10561       0.558872\n",
       "270          308            year         10450       0.552998"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_doc_count.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_index</th>\n",
       "      <th>word</th>\n",
       "      <th>num_articles</th>\n",
       "      <th>perc_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40956</th>\n",
       "      <td>40956</td>\n",
       "      <td>mcawesome</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40955</th>\n",
       "      <td>40957</td>\n",
       "      <td>pickard</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40954</th>\n",
       "      <td>40954</td>\n",
       "      <td>pointlessness</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40953</th>\n",
       "      <td>40953</td>\n",
       "      <td>kilic</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40949</th>\n",
       "      <td>40949</td>\n",
       "      <td>smallfuck</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40948</th>\n",
       "      <td>40947</td>\n",
       "      <td>is_stalemate</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40947</th>\n",
       "      <td>40950</td>\n",
       "      <td>white_has_won</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40946</th>\n",
       "      <td>40945</td>\n",
       "      <td>apply_move</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40943</th>\n",
       "      <td>40941</td>\n",
       "      <td>lovelace</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65250</th>\n",
       "      <td>65250</td>\n",
       "      <td>justicemate</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_index           word  num_articles  perc_articles\n",
       "40956       40956      mcawesome             1       0.000053\n",
       "40955       40957        pickard             1       0.000053\n",
       "40954       40954  pointlessness             1       0.000053\n",
       "40953       40953          kilic             1       0.000053\n",
       "40949       40949      smallfuck             1       0.000053\n",
       "40948       40947   is_stalemate             1       0.000053\n",
       "40947       40950  white_has_won             1       0.000053\n",
       "40946       40945     apply_move             1       0.000053\n",
       "40943       40941       lovelace             1       0.000053\n",
       "65250       65250    justicemate             1       0.000053"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_doc_count.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65251"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out words in 60%+ of articles or in less than 50 articles\n",
    "id2word.filter_extremes(no_above=0.60, no_below=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5841"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild the corpus with the filtered dictionary\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim LDA Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_grid_search(corpus, id2word, rs, num_topics, decay, per_word_topics, update_every, alpha, chunksize, passes, iterations):\n",
    "    \"\"\"\n",
    "    Given a corpus and dictionary, run through all combinations of given Gensim LDA parameters.\n",
    "    Return a dataframe with the results, sorted by coherence.\n",
    "    This can take hours to run depending on the number of parameters supplied.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        x = 0\n",
    "\n",
    "        coherence_values = []\n",
    "        perplexity_values = []\n",
    "\n",
    "        num_topics_list = []\n",
    "        decay_list = []\n",
    "        per_word_topics_list = []\n",
    "        update_every_list = []\n",
    "        alpha_list = []\n",
    "        chunksize_list = []\n",
    "        passes_list = []\n",
    "        iterations_list = []\n",
    "\n",
    "        for i in product(num_topics, decay, per_word_topics, update_every, alpha, chunksize, passes, iterations):\n",
    "            model = gensim.models.ldamodel.LdaModel(corpus=corpus, \n",
    "                                                    num_topics=i[0], \n",
    "                                                    id2word=id2word,\n",
    "                                                    decay=i[1],\n",
    "                                                    per_word_topics=i[2],\n",
    "                                                    update_every=i[3],\n",
    "                                                    alpha=i[4],\n",
    "                                                    chunksize=i[5],\n",
    "                                                    passes=i[6],\n",
    "                                                    iterations=i[7],\n",
    "                                                    random_state=rs)\n",
    "\n",
    "            coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "            coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "            perplexity_values.append(model.log_perplexity(corpus))\n",
    "\n",
    "            num_topics_list.append(i[0])\n",
    "            decay_list.append(i[1])\n",
    "            per_word_topics_list.append(i[2])\n",
    "            update_every_list.append(i[3])\n",
    "            alpha_list.append(i[4])\n",
    "            chunksize_list.append(i[5])\n",
    "            passes_list.append(i[6])\n",
    "            iterations_list.append(i[7])\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        length = len(iterations_list)\n",
    "        num_topics_list = num_topics_list[0 : length]\n",
    "        decay_list = decay_list[0 : length]\n",
    "        per_word_topics_list = per_word_topics_list[0 : length]\n",
    "        update_every_list = update_every_list[0 : length]\n",
    "        alpha_list = alpha_list[0 : length]\n",
    "        chunksize_list = chunksize_list[0 : length]\n",
    "        passes_list = passes_list[0 : length]\n",
    "        iterations_list = iterations_list[0 : length]\n",
    "\n",
    "    finally:\n",
    "        lda_parameter_df = pd.DataFrame({'coherence' : coherence_values,\n",
    "                                         'perplexity' : perplexity_values,\n",
    "                                         'num_topics' : num_topics_list,\n",
    "                                         'decay' : decay_list,\n",
    "                                         'per_word_topics' : per_word_topics_list,\n",
    "                                         'update_every' : update_every_list,\n",
    "                                         'alpha' : alpha_list,\n",
    "                                         'chunksize' : chunksize_list,\n",
    "                                         'passes' : passes_list,\n",
    "                                         'iterations' : iterations_list,\n",
    "                                        })\n",
    "\n",
    "        lda_parameter_df.sort_values('coherence', ascending=False)\n",
    "\n",
    "        return lda_parameter_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Tuning - Round 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up lists of parameters\n",
    "num_topics = [20, 25, 30, 35, 40]\n",
    "decay = [0.5, 0.75, 1.0]\n",
    "per_word_topics = [True, False]\n",
    "update_every = [0, 1, 2]\n",
    "alpha = ['auto', 'symmetric', 'asymmetric']\n",
    "chunksize = [1000]\n",
    "passes = [1]\n",
    "iterations = [100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get performance df\n",
    "lda_parameter_df = lda_grid_search(corpus, id2word, rs, num_topics, decay, per_word_topics, \n",
    "                                   update_every, alpha, chunksize, passes, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coherence</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>num_topics</th>\n",
       "      <th>decay</th>\n",
       "      <th>per_word_topics</th>\n",
       "      <th>update_every</th>\n",
       "      <th>alpha</th>\n",
       "      <th>chunksize</th>\n",
       "      <th>passes</th>\n",
       "      <th>iterations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.517308</td>\n",
       "      <td>-7.485459</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.517308</td>\n",
       "      <td>-7.485459</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.505328</td>\n",
       "      <td>-7.445682</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.505328</td>\n",
       "      <td>-7.445682</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.504658</td>\n",
       "      <td>-7.480384</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.504658</td>\n",
       "      <td>-7.484003</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.504658</td>\n",
       "      <td>-7.480384</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.504658</td>\n",
       "      <td>-7.484003</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.501112</td>\n",
       "      <td>-7.582662</td>\n",
       "      <td>35</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.501112</td>\n",
       "      <td>-7.582662</td>\n",
       "      <td>35</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.500624</td>\n",
       "      <td>-7.641932</td>\n",
       "      <td>40</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0.500624</td>\n",
       "      <td>-7.641932</td>\n",
       "      <td>40</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.500390</td>\n",
       "      <td>-7.649564</td>\n",
       "      <td>40</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.500390</td>\n",
       "      <td>-7.649564</td>\n",
       "      <td>40</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.500208</td>\n",
       "      <td>-7.588234</td>\n",
       "      <td>35</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.500208</td>\n",
       "      <td>-7.588234</td>\n",
       "      <td>35</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.500041</td>\n",
       "      <td>-7.444736</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500041</td>\n",
       "      <td>-7.444736</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.498072</td>\n",
       "      <td>-7.442286</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.498072</td>\n",
       "      <td>-7.442286</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     coherence  perplexity  num_topics  decay  per_word_topics  update_every  \\\n",
       "59    0.517308   -7.485459          25    0.5             True             1   \n",
       "68    0.517308   -7.485459          25    0.5            False             1   \n",
       "14    0.505328   -7.445682          20    0.5            False             1   \n",
       "5     0.505328   -7.445682          20    0.5             True             1   \n",
       "57    0.504658   -7.480384          25    0.5             True             1   \n",
       "58    0.504658   -7.484003          25    0.5             True             1   \n",
       "66    0.504658   -7.480384          25    0.5            False             1   \n",
       "67    0.504658   -7.484003          25    0.5            False             1   \n",
       "165   0.501112   -7.582662          35    0.5             True             1   \n",
       "174   0.501112   -7.582662          35    0.5            False             1   \n",
       "228   0.500624   -7.641932          40    0.5            False             1   \n",
       "219   0.500624   -7.641932          40    0.5             True             1   \n",
       "229   0.500390   -7.649564          40    0.5            False             1   \n",
       "220   0.500390   -7.649564          40    0.5             True             1   \n",
       "166   0.500208   -7.588234          35    0.5             True             1   \n",
       "175   0.500208   -7.588234          35    0.5            False             1   \n",
       "13    0.500041   -7.444736          20    0.5            False             1   \n",
       "4     0.500041   -7.444736          20    0.5             True             1   \n",
       "12    0.498072   -7.442286          20    0.5            False             1   \n",
       "3     0.498072   -7.442286          20    0.5             True             1   \n",
       "\n",
       "          alpha  chunksize  passes  iterations  \n",
       "59   asymmetric       1000       1         100  \n",
       "68   asymmetric       1000       1         100  \n",
       "14   asymmetric       1000       1         100  \n",
       "5    asymmetric       1000       1         100  \n",
       "57         auto       1000       1         100  \n",
       "58    symmetric       1000       1         100  \n",
       "66         auto       1000       1         100  \n",
       "67    symmetric       1000       1         100  \n",
       "165        auto       1000       1         100  \n",
       "174        auto       1000       1         100  \n",
       "228        auto       1000       1         100  \n",
       "219        auto       1000       1         100  \n",
       "229   symmetric       1000       1         100  \n",
       "220   symmetric       1000       1         100  \n",
       "166   symmetric       1000       1         100  \n",
       "175   symmetric       1000       1         100  \n",
       "13    symmetric       1000       1         100  \n",
       "4     symmetric       1000       1         100  \n",
       "12         auto       1000       1         100  \n",
       "3          auto       1000       1         100  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the performance of tested combos\n",
    "lda_parameter_df.sort_values('coherence', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Tuning - Round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up lists of parameters\n",
    "num_topics = [23, 25, 27]\n",
    "decay = [0.5]\n",
    "per_word_topics = [True]\n",
    "update_every = [1]\n",
    "alpha = ['auto', 'symmetric', 'asymmetric']\n",
    "chunksize = [1000, 500, 100]\n",
    "passes = [1]\n",
    "iterations = [100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the performance df\n",
    "lda_parameter_df2 = lda_grid_search(corpus, id2word, rs, num_topics, decay, per_word_topics, \n",
    "                                   update_every, alpha, chunksize, passes, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coherence</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>num_topics</th>\n",
       "      <th>decay</th>\n",
       "      <th>per_word_topics</th>\n",
       "      <th>update_every</th>\n",
       "      <th>alpha</th>\n",
       "      <th>chunksize</th>\n",
       "      <th>passes</th>\n",
       "      <th>iterations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.517308</td>\n",
       "      <td>-7.485459</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.511666</td>\n",
       "      <td>-7.467108</td>\n",
       "      <td>23</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.510463</td>\n",
       "      <td>-7.462797</td>\n",
       "      <td>23</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.509711</td>\n",
       "      <td>-7.465809</td>\n",
       "      <td>23</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.504658</td>\n",
       "      <td>-7.484003</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.504658</td>\n",
       "      <td>-7.480384</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.494275</td>\n",
       "      <td>-7.919394</td>\n",
       "      <td>23</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.494078</td>\n",
       "      <td>-7.912356</td>\n",
       "      <td>23</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.492529</td>\n",
       "      <td>-8.045482</td>\n",
       "      <td>27</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.490836</td>\n",
       "      <td>-8.061535</td>\n",
       "      <td>27</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.489053</td>\n",
       "      <td>-8.054749</td>\n",
       "      <td>27</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.488221</td>\n",
       "      <td>-7.516078</td>\n",
       "      <td>27</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.486684</td>\n",
       "      <td>-7.514298</td>\n",
       "      <td>27</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.485227</td>\n",
       "      <td>-7.510510</td>\n",
       "      <td>27</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.484916</td>\n",
       "      <td>-8.007541</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.484258</td>\n",
       "      <td>-7.920884</td>\n",
       "      <td>23</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.483928</td>\n",
       "      <td>-9.982413</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.482288</td>\n",
       "      <td>-7.994035</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.478616</td>\n",
       "      <td>-8.002570</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.476563</td>\n",
       "      <td>-10.151196</td>\n",
       "      <td>27</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    coherence  perplexity  num_topics  decay  per_word_topics  update_every  \\\n",
       "15   0.517308   -7.485459          25    0.5             True             1   \n",
       "6    0.511666   -7.467108          23    0.5             True             1   \n",
       "0    0.510463   -7.462797          23    0.5             True             1   \n",
       "3    0.509711   -7.465809          23    0.5             True             1   \n",
       "12   0.504658   -7.484003          25    0.5             True             1   \n",
       "9    0.504658   -7.480384          25    0.5             True             1   \n",
       "4    0.494275   -7.919394          23    0.5             True             1   \n",
       "1    0.494078   -7.912356          23    0.5             True             1   \n",
       "19   0.492529   -8.045482          27    0.5             True             1   \n",
       "25   0.490836   -8.061535          27    0.5             True             1   \n",
       "22   0.489053   -8.054749          27    0.5             True             1   \n",
       "24   0.488221   -7.516078          27    0.5             True             1   \n",
       "21   0.486684   -7.514298          27    0.5             True             1   \n",
       "18   0.485227   -7.510510          27    0.5             True             1   \n",
       "16   0.484916   -8.007541          25    0.5             True             1   \n",
       "7    0.484258   -7.920884          23    0.5             True             1   \n",
       "11   0.483928   -9.982413          25    0.5             True             1   \n",
       "10   0.482288   -7.994035          25    0.5             True             1   \n",
       "13   0.478616   -8.002570          25    0.5             True             1   \n",
       "20   0.476563  -10.151196          27    0.5             True             1   \n",
       "\n",
       "         alpha  chunksize  passes  iterations  \n",
       "15  asymmetric       1000       1         100  \n",
       "6   asymmetric       1000       1         100  \n",
       "0         auto       1000       1         100  \n",
       "3    symmetric       1000       1         100  \n",
       "12   symmetric       1000       1         100  \n",
       "9         auto       1000       1         100  \n",
       "4    symmetric        500       1         100  \n",
       "1         auto        500       1         100  \n",
       "19        auto        500       1         100  \n",
       "25  asymmetric        500       1         100  \n",
       "22   symmetric        500       1         100  \n",
       "24  asymmetric       1000       1         100  \n",
       "21   symmetric       1000       1         100  \n",
       "18        auto       1000       1         100  \n",
       "16  asymmetric        500       1         100  \n",
       "7   asymmetric        500       1         100  \n",
       "11        auto        100       1         100  \n",
       "10        auto        500       1         100  \n",
       "13   symmetric        500       1         100  \n",
       "20        auto        100       1         100  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the performance for all tested combos\n",
    "lda_parameter_df2.sort_values('coherence', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Tuning - Round 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the lists of parameters\n",
    "num_topics = [25]\n",
    "decay = [0.5]\n",
    "per_word_topics = [True]\n",
    "update_every = [1]\n",
    "alpha = ['asymmetric']\n",
    "chunksize = [1000, 1500, 2000]\n",
    "passes = [1, 3]\n",
    "iterations = [100, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the performance df\n",
    "lda_parameter_df3 = lda_grid_search(corpus, id2word, rs, num_topics, decay, per_word_topics, \n",
    "                                   update_every, alpha, chunksize, passes, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coherence</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>num_topics</th>\n",
       "      <th>decay</th>\n",
       "      <th>per_word_topics</th>\n",
       "      <th>update_every</th>\n",
       "      <th>alpha</th>\n",
       "      <th>chunksize</th>\n",
       "      <th>passes</th>\n",
       "      <th>iterations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.527104</td>\n",
       "      <td>-7.339544</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>1500</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.525307</td>\n",
       "      <td>-7.461150</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.519405</td>\n",
       "      <td>-7.445168</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.517308</td>\n",
       "      <td>-7.485459</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.514528</td>\n",
       "      <td>-7.280307</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.512899</td>\n",
       "      <td>-7.269218</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.511997</td>\n",
       "      <td>-7.330817</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>1500</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.503808</td>\n",
       "      <td>-7.500432</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.496147</td>\n",
       "      <td>-7.388813</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>1500</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.494058</td>\n",
       "      <td>-7.378056</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>1500</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.487144</td>\n",
       "      <td>-7.325543</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.487079</td>\n",
       "      <td>-7.335416</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    coherence  perplexity  num_topics  decay  per_word_topics  update_every  \\\n",
       "7    0.527104   -7.339544          25    0.5             True             1   \n",
       "3    0.525307   -7.461150          25    0.5             True             1   \n",
       "2    0.519405   -7.445168          25    0.5             True             1   \n",
       "0    0.517308   -7.485459          25    0.5             True             1   \n",
       "11   0.514528   -7.280307          25    0.5             True             1   \n",
       "10   0.512899   -7.269218          25    0.5             True             1   \n",
       "6    0.511997   -7.330817          25    0.5             True             1   \n",
       "1    0.503808   -7.500432          25    0.5             True             1   \n",
       "5    0.496147   -7.388813          25    0.5             True             1   \n",
       "4    0.494058   -7.378056          25    0.5             True             1   \n",
       "8    0.487144   -7.325543          25    0.5             True             1   \n",
       "9    0.487079   -7.335416          25    0.5             True             1   \n",
       "\n",
       "         alpha  chunksize  passes  iterations  \n",
       "7   asymmetric       1500       3         200  \n",
       "3   asymmetric       1000       3         200  \n",
       "2   asymmetric       1000       3         100  \n",
       "0   asymmetric       1000       1         100  \n",
       "11  asymmetric       2000       3         200  \n",
       "10  asymmetric       2000       3         100  \n",
       "6   asymmetric       1500       3         100  \n",
       "1   asymmetric       1000       1         200  \n",
       "5   asymmetric       1500       1         200  \n",
       "4   asymmetric       1500       1         100  \n",
       "8   asymmetric       2000       1         100  \n",
       "9   asymmetric       2000       1         200  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the performance results for all tested combos\n",
    "lda_parameter_df3.sort_values('coherence', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence:  0.523430550686085\n"
     ]
    }
   ],
   "source": [
    "# Select the model with the best combination of coherence and perplexity\n",
    "optimal_model = gensim.models.ldamodel.LdaModel(corpus=corpus, \n",
    "                                                num_topics=25, \n",
    "                                                id2word=id2word,\n",
    "                                                decay=0.5,\n",
    "                                                per_word_topics=True,\n",
    "                                                update_every=1,\n",
    "                                                alpha='asymmetric',\n",
    "                                                chunksize=1500,\n",
    "                                                passes=10,\n",
    "                                                iterations=200, \n",
    "                                                random_state=rs)\n",
    "\n",
    "coherencemodel = CoherenceModel(model=optimal_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "print('Coherence: ',coherencemodel.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.016*\"blockchain\" + 0.014*\"technology\" + 0.013*\"world\" + 0.010*\"people\" + '\n",
      "  '0.009*\"new\" + 0.009*\"community\" + 0.008*\"work\" + 0.008*\"help\" + '\n",
      "  '0.008*\"first\" + 0.007*\"project\"'),\n",
      " (1,\n",
      "  '0.041*\"network\" + 0.024*\"blockchain\" + 0.020*\"lightning\" + '\n",
      "  '0.017*\"transaction\" + 0.015*\"ethereum\" + 0.014*\"project\" + 0.014*\"use\" + '\n",
      "  '0.014*\"protocol\" + 0.012*\"token\" + 0.012*\"developer\"'),\n",
      " (2,\n",
      "  '0.036*\"claim\" + 0.034*\"court\" + 0.022*\"case\" + 0.020*\"file\" + 0.019*\"legal\" '\n",
      "  '+ 0.019*\"order\" + 0.019*\"document\" + 0.011*\"lawsuit\" + 0.010*\"allege\" + '\n",
      "  '0.010*\"sale\"'),\n",
      " (3,\n",
      "  '0.035*\"attack\" + 0.031*\"hack\" + 0.031*\"steal\" + 0.026*\"security\" + '\n",
      "  '0.024*\"scam\" + 0.024*\"fund\" + 0.021*\"hacker\" + 0.021*\"report\" + '\n",
      "  '0.018*\"account\" + 0.015*\"user\"'),\n",
      " (4,\n",
      "  '0.036*\"company\" + 0.031*\"crypto\" + 0.022*\"service\" + 0.016*\"new\" + '\n",
      "  '0.014*\"bank\" + 0.013*\"announce\" + 0.013*\"platform\" + 0.013*\"launch\" + '\n",
      "  '0.012*\"customer\" + 0.011*\"exchange\"'),\n",
      " (5,\n",
      "  '0.023*\"country\" + 0.014*\"government\" + 0.013*\"report\" + 0.013*\"use\" + '\n",
      "  '0.012*\"tax\" + 0.011*\"exchange\" + 0.009*\"india\" + 0.009*\"crypto\" + '\n",
      "  '0.009*\"local\" + 0.008*\"bank\"'),\n",
      " (6,\n",
      "  '0.041*\"price\" + 0.019*\"high\" + 0.012*\"see\" + 0.012*\"week\" + 0.011*\"low\" + '\n",
      "  '0.010*\"trader\" + 0.010*\"drop\" + 0.008*\"day\" + 0.007*\"level\" + '\n",
      "  '0.007*\"month\"'),\n",
      " (7,\n",
      "  '0.042*\"usd\" + 0.042*\"level\" + 0.041*\"support\" + 0.035*\"bull\" + '\n",
      "  '0.029*\"break\" + 0.028*\"price\" + 0.028*\"resistance\" + 0.023*\"pair\" + '\n",
      "  '0.017*\"bear\" + 0.015*\"suggest\"'),\n",
      " (8,\n",
      "  '0.241*\"cash\" + 0.194*\"bch\" + 0.019*\"coin\" + 0.018*\"fork\" + 0.012*\"read\" + '\n",
      "  '0.009*\"abc\" + 0.009*\"support\" + 0.009*\"com\" + 0.008*\"august\" + '\n",
      "  '0.008*\"core\"'),\n",
      " (9,\n",
      "  '0.101*\"mining\" + 0.038*\"miner\" + 0.017*\"bitmain\" + 0.013*\"company\" + '\n",
      "  '0.013*\"energy\" + 0.012*\"pool\" + 0.012*\"power\" + 0.011*\"electricity\" + '\n",
      "  '0.010*\"operation\" + 0.010*\"mine\"'),\n",
      " (10,\n",
      "  '0.019*\"twitter\" + 0.015*\"tweet\" + 0.014*\"crypto\" + 0.013*\"say\" + '\n",
      "  '0.012*\"wright\" + 0.009*\"claim\" + 0.009*\"post\" + 0.007*\"community\" + '\n",
      "  '0.007*\"satoshi\" + 0.007*\"call\"'),\n",
      " (11,\n",
      "  '0.017*\"go\" + 0.013*\"say\" + 0.013*\"people\" + 0.011*\"make\" + 0.011*\"get\" + '\n",
      "  '0.010*\"think\" + 0.009*\"year\" + 0.009*\"even\" + 0.009*\"money\" + 0.009*\"take\"'),\n",
      " (12,\n",
      "  '0.048*\"wallet\" + 0.042*\"user\" + 0.020*\"use\" + 0.011*\"app\" + 0.009*\"new\" + '\n",
      "  '0.009*\"allow\" + 0.008*\"service\" + 0.008*\"platform\" + 0.008*\"send\" + '\n",
      "  '0.007*\"feature\"'),\n",
      " (13,\n",
      "  '0.060*\"game\" + 0.049*\"donation\" + 0.048*\"lee\" + 0.031*\"trump\" + '\n",
      "  '0.030*\"litecoin\" + 0.025*\"election\" + 0.024*\"player\" + 0.023*\"bet\" + '\n",
      "  '0.023*\"campaign\" + 0.022*\"fund\"'),\n",
      " (14,\n",
      "  '0.055*\"transaction\" + 0.039*\"fee\" + 0.038*\"network\" + 0.024*\"block\" + '\n",
      "  '0.022*\"halve\" + 0.021*\"miner\" + 0.020*\"increase\" + 0.016*\"high\" + '\n",
      "  '0.012*\"hash_rate\" + 0.011*\"number\"'),\n",
      " (15,\n",
      "  '0.036*\"address\" + 0.028*\"transaction\" + 0.022*\"coin\" + 0.021*\"use\" + '\n",
      "  '0.019*\"datum\" + 0.016*\"wallet\" + 0.014*\"blockchain\" + 0.012*\"number\" + '\n",
      "  '0.012*\"privacy\" + 0.012*\"dec\"'),\n",
      " (16,\n",
      "  '0.063*\"payment\" + 0.035*\"accept\" + 0.026*\"use\" + 0.022*\"pay\" + '\n",
      "  '0.020*\"purchase\" + 0.017*\"merchant\" + 0.013*\"buy\" + 0.013*\"store\" + '\n",
      "  '0.012*\"bitpay\" + 0.010*\"atms\"'),\n",
      " (17,\n",
      "  '0.060*\"future\" + 0.035*\"exchange\" + 0.032*\"etf\" + 0.031*\"contract\" + '\n",
      "  '0.024*\"sec\" + 0.023*\"bakkt\" + 0.020*\"cme\" + 0.019*\"trade\" + 0.016*\"launch\" '\n",
      "  '+ 0.014*\"option\"'),\n",
      " (18,\n",
      "  '0.054*\"percent\" + 0.039*\"coin\" + 0.037*\"day\" + 0.030*\"ethereum\" + '\n",
      "  '0.027*\"altcoin\" + 0.026*\"price\" + 0.023*\"crypto\" + 0.019*\"cap\" + '\n",
      "  '0.019*\"hour\" + 0.018*\"xrp\"'),\n",
      " (19,\n",
      "  '0.050*\"investor\" + 0.040*\"asset\" + 0.040*\"investment\" + 0.024*\"fund\" + '\n",
      "  '0.023*\"institutional\" + 0.018*\"firm\" + 0.017*\"crypto\" + 0.016*\"digital\" + '\n",
      "  '0.015*\"company\" + 0.015*\"invest\"'),\n",
      " (20,\n",
      "  '0.027*\"blockchain\" + 0.022*\"crypto\" + 0.022*\"china\" + 0.014*\"say\" + '\n",
      "  '0.013*\"technology\" + 0.012*\"chinese\" + 0.011*\"digital\" + 0.011*\"financial\" '\n",
      "  '+ 0.011*\"state\" + 0.011*\"government\"'),\n",
      " (21,\n",
      "  '0.024*\"gold\" + 0.021*\"price\" + 0.017*\"year\" + 0.014*\"asset\" + 0.012*\"stock\" '\n",
      "  '+ 0.011*\"value\" + 0.010*\"increase\" + 0.009*\"global\" + 0.009*\"high\" + '\n",
      "  '0.009*\"investor\"'),\n",
      " (22,\n",
      "  '0.090*\"exchange\" + 0.046*\"trading\" + 0.035*\"volume\" + 0.028*\"trade\" + '\n",
      "  '0.018*\"platform\" + 0.014*\"trader\" + 0.012*\"binance\" + 0.011*\"large\" + '\n",
      "  '0.011*\"crypto\" + 0.011*\"bitfinex\"'),\n",
      " (23,\n",
      "  '0.043*\"segwit\" + 0.020*\"fork\" + 0.020*\"support\" + 0.019*\"core\" + '\n",
      "  '0.018*\"block\" + 0.014*\"miner\" + 0.014*\"chain\" + 0.013*\"community\" + '\n",
      "  '0.012*\"network\" + 0.011*\"developer\"'),\n",
      " (24,\n",
      "  '0.039*\"currency\" + 0.018*\"digital\" + 0.017*\"system\" + 0.017*\"money\" + '\n",
      "  '0.013*\"use\" + 0.012*\"government\" + 0.011*\"value\" + 0.010*\"financial\" + '\n",
      "  '0.008*\"bank\" + 0.008*\"control\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the topics from the model with top 10 keywords\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10, num_topics=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the topic modeling model\n",
    "with open('sentiment_pickles/pickle_lda_model.pickle', 'wb') as to_write:\n",
    "    pickle.dump(optimal_model, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the optimal topic model (if re-starting here)\n",
    "with open('sentiment_pickles/pickle_lda_model.pickle', 'rb') as read_file:\n",
    "    optimal_model = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Topic Breakdowns by Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save topic distributions by article to an array\n",
    "topics_by_doc = optimal_model.get_document_topics(corpus, minimum_probability=0.0)\n",
    "topics_by_doc = gensim.matutils.corpus2csc(topics_by_doc)\n",
    "topics_by_doc = topics_by_doc.T.toarray()\n",
    "topics_by_doc = pd.DataFrame(topics_by_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.335196</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.088789</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.525360</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.029469</td>\n",
       "      <td>0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.470946</td>\n",
       "      <td>0.016316</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020382</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060696</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.061421</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.176254</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.440862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.185862</td>\n",
       "      <td>0.070506</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.072194</td>\n",
       "      <td>0.138473</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.030261</td>\n",
       "      <td>0.096304</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016993</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.096651</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.056455</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.609697</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.075541</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.000919  0.000765  0.014290  0.000574  0.335196  0.000459  0.000417   \n",
       "1  0.470946  0.016316  0.000498  0.000435  0.000387  0.000348  0.000317   \n",
       "2  0.060696  0.000577  0.061421  0.000433  0.176254  0.000346  0.000315   \n",
       "3  0.072194  0.138473  0.000272  0.030261  0.096304  0.000190  0.000173   \n",
       "4  0.152250  0.000837  0.056455  0.000628  0.609697  0.000502  0.000457   \n",
       "\n",
       "         7         8         9   ...        15        16        17        18  \\\n",
       "0  0.000383  0.000353  0.000328  ...  0.000230  0.000219  0.088789  0.000200   \n",
       "1  0.000290  0.000268  0.000249  ...  0.020382  0.000166  0.000158  0.000151   \n",
       "2  0.000288  0.000266  0.440862  ...  0.000173  0.000165  0.000157  0.000150   \n",
       "3  0.000159  0.000146  0.000136  ...  0.016993  0.000091  0.000086  0.000083   \n",
       "4  0.000419  0.000386  0.000359  ...  0.000251  0.000239  0.000228  0.000218   \n",
       "\n",
       "         19        20        21        22        23        24  \n",
       "0  0.525360  0.000184  0.000177  0.000170  0.029469  0.000158  \n",
       "1  0.000145  0.000139  0.000134  0.000129  0.000124  0.000120  \n",
       "2  0.185862  0.070506  0.000133  0.000128  0.000124  0.000119  \n",
       "3  0.000079  0.000076  0.000073  0.000070  0.096651  0.000066  \n",
       "4  0.075541  0.000201  0.000193  0.000186  0.000179  0.000173  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_by_doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the topic model breakdown by article\n",
    "with open('sentiment_pickles/pickle_topics_by_article.pickle', 'wb') as to_write:\n",
    "    pickle.dump(topics_by_doc, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Topic Modeling and Determine Topic Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(optimal_model, corpus, id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_string = pyLDAvis.prepared_data_to_html(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the pyLDAvis html for presentation elsewhere\n",
    "with open('sentiment_pickles/pickle_pyLDAvis.pickle', 'wb') as to_write:\n",
    "    pickle.dump(html_string, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label the pyLDAvis topics\n",
    "topic_labels = {'topic_1' : 'Famous Investors',\n",
    "                'topic_2' : 'Bull Run',\n",
    "                'topic_3' : 'Bitcoin as a Commodity',\n",
    "                'topic_4' : 'Education',\n",
    "                'topic_5' : 'Global Adoption',\n",
    "                'topic_6' : 'Crypto Founders',\n",
    "                'topic_7' : 'Price Analysis',\n",
    "                'topic_8' : 'Bitcoin as a Currency',\n",
    "                'topic_9' : 'Security',\n",
    "                'topic_10' : 'Blockchain Innovation',\n",
    "                'topic_11' : 'Government Regulation',\n",
    "                'topic_12' : 'Crime',\n",
    "                'topic_13' : 'Peer-to-Peer',\n",
    "                'topic_14' : 'Institutitonal Investing',\n",
    "                'topic_15' : 'Price Movement',\n",
    "                'topic_16' : 'Mining',\n",
    "                'topic_17' : 'Privacy',\n",
    "                'topic_18' : 'Bitcoin ETF',\n",
    "                'topic_19' : 'Bitcoin Improvement Proposals (BIP)',\n",
    "                'topic_20' : 'Transaction Fees',\n",
    "                'topic_21' : 'Pay with Bitcoin',\n",
    "                'topic_22' : 'Bitcoin Cash (BCH)',\n",
    "                'topic_23' : 'Lawsuits',\n",
    "                'topic_24' : 'Hacks',\n",
    "                'topic_25' : 'Community (Games, Charity)',\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save topic labels dataframe for use in TokenSense\n",
    "label_df = pd.DataFrame({'Topic' : topic_labels.keys(), 'Label' : topic_labels.values()})\n",
    "label_df['Topic'] = label_df['Topic'].str.replace('topic_', 'Topic ')\n",
    "\n",
    "label_df.to_csv('sentiment_pickles/topic_labels.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
